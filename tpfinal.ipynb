{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introducción y motivación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Dataset elegido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset de Uso de taxis Yellow Cab en USA en el año 2020.\n",
    "https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORTS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ydata_profiling import ProfileReport\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomamos los registros de los viajes de los Yellow Taxis en Nueva York de los meses del verano (julio, agosto y septiembre del año 2020), dado que el total de viajes del 2020 superaba los 24.000.000 de registros y no se podia trabajar con la libreria pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3148715, 19)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ruta del archivo Parquet\n",
    "file_path = 'dataset/dataset.parquet'\n",
    "\n",
    "# Leer el archivo usando Pandas\n",
    "df = pd.read_parquet(file_path)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Análisis exploratorio inicial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Visualizar las primeras filas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Realizar un resumen de 5 números."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().loc[['min', '25%', '50%', '75%', 'max']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Identificar los tipos de datos: categórico, ordinal, etc. Responder para cada variable su tipo y si es informativa para un problema de clasificación (por ejemplo si se trata de un código, como una matrícula, o un nombre propio)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar tipos de datos\n",
    "data_types = df.dtypes\n",
    "\n",
    "# Clasificación de tipos de datos\n",
    "type_classification = {}\n",
    "for column in df.columns:\n",
    "    dtype = data_types[column]\n",
    "    if pd.api.types.is_string_dtype(dtype):\n",
    "        type_classification[column] = 'Categórico/Textual'\n",
    "    elif pd.api.types.is_numeric_dtype(dtype):\n",
    "        type_classification[column] = 'Numérico'\n",
    "    elif pd.api.types.is_datetime64_any_dtype(dtype):\n",
    "        type_classification[column] = 'Temporal'\n",
    "    else:\n",
    "        type_classification[column] = 'Otro'\n",
    "\n",
    "# Evaluación de la informatividad para clasificación\n",
    "informative_columns = {}\n",
    "for column in df.columns:\n",
    "    if type_classification[column] in ['Categórico/Textual', 'Numérico', 'Temporal']:\n",
    "        # Heurística: los códigos únicos y nombres propios no son informativos\n",
    "        if column.lower() in ['id', 'name', 'matricula', 'codigo','airport_fee','store_and_fwd_flag']:\n",
    "            informative_columns[column] = 'No Informativa'\n",
    "        else:\n",
    "            informative_columns[column] = 'Informativa'\n",
    "    else:\n",
    "        informative_columns[column] = 'No Informativa'\n",
    "\n",
    "# Crear un dataframe con la clasificación y evaluación\n",
    "result_df = pd.DataFrame({\n",
    "    'Tipo de Dato': [type_classification[col] for col in df.columns],\n",
    "    'Informativa para Clasificación': [informative_columns[col] for col in df.columns]\n",
    "}, index=df.columns)\n",
    "\n",
    "\n",
    "# Mostrar el dataframe resultante\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando pandas profiling\n",
    "report = ProfileReport(df, title='Yellow Taxis in NY', minimal=True)\n",
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, casi todas las variables son informativas debido a la naturaleza intrinseca del dataset, ya que la descripcion de cada variable implica y explica una relacion directa con la variable de salida seleccionada. Más adelante veremos la relacion directa entre cada variable de entrada y la variable de salida.\n",
    "\n",
    "- store_and_fwd_flag: No es informativa debido a que no aporta ningun tipo de criterio util segun la descripcion de la variable, ademas de tener muchos valores nulos.\n",
    "- airport_fee: No es informativa debido a que solo hay un solo valor para esta variable en todo el dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Identificar las variables de entrada y de salida del problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todas menos total_amount son variables de entrada. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Variables de entrada:\n",
    "  - Realizar los siguientes análisis por tipo de variable:\n",
    "    - **Numéricas:** Obtener conclusiones acerca de la distribución de los datos.\n",
    "    - **Categorías:** Obtener conclusiones acerca de la cardinalidad, representación de cada categoría, etc.\n",
    "    - **Compuestas:** ¿Pueden tratarse para utilizarse en el problema a resolver?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = df.drop(columns=['total_amount'])\n",
    "features_df.hist(bins=30,log=False,figsize=(15,15))\n",
    "plt.suptitle('Histogramas de Atributos y Target')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables de salida (en caso de aplicar): \n",
    "o ¿Están balanceadas las clases? \n",
    "o (en caso de aplicar) ¿Qué técnicas consideraría para codificar la variable de salida? \n",
    "Justifique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustar las opciones de visualización para mostrar los números en formato estándar\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "\n",
    "# Resumen estadístico\n",
    "describe_stats = df['total_amount'].describe()\n",
    "print(describe_stats)\n",
    "\n",
    "sns.histplot(df['total_amount'], kde=False, bins=90,log_scale=True)\n",
    "plt.xlabel('Valor')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.title('Histograma con Seaborn')\n",
    "plt.show()\n",
    "\n",
    "# Crear un gráfico de caja\n",
    "sns.boxplot(data=df, y='total_amount', log_scale=True)\n",
    "plt.title('Gráfico de Caja')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Limpieza y preparación de datos / ingeniería de features\n",
    "- Antes de entrenar un modelo de aprendizaje automático, ¿podría identificar las variables de entrada de mayor importancia? Considerar por lo menos dos técnicas para cada variable. Explique brevemente los métodos utilizados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Datos faltantes. Indicar cantidad de observaciones y valores faltantes para cada variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - ¿Qué supuestos puede realizar acerca de los datos faltantes? ¿Qué técnicas de imputación recomendaría? Ensayar distintas técnicas y analizar los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - a. Eliminacion de columnas: Eliminaremos columnas completas que tienen un alto porcentaje de datos faltantes. \n",
    "\n",
    "En este caso, airport_fee tiene 2357493 datos faltantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminar columna\n",
    "df.drop(columns=['airport_fee'], inplace=True)\n",
    "\n",
    "#Validar nuevo dataset sin la columna 'airport_fee'              \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - b. Eliminacion de datos faltantes: Eliminaremos las observaciones que contengan valores nulos en 'passenger_count', 'RatecodeID', 'congestion_surcharge' y 'store_and_fwd_flag'. Esto porque los valores no aportan informacion relevante a nuestra variable de salida y representan un numero reducido de muestras en la cuenta total de observaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminar valores nulos\n",
    "df.dropna(inplace=True)\n",
    "#Validar\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - En función del estudio inicial de las variables que se hizo en la sección anterior, elegir una técnica de codificación para cada variable. Cuando lo considere apropiado, ensayar distintas técnicas y comparar los resultados, teniendo en cuenta el tipo de clasificador a utilizar. Nota: para tipos de datos compuestos o estructurados, considerar la obtención de variables de tipo numérico/categórico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Vamos a implementar Binary Encoding en unica variable categorica que tenemos para reemplazar los valores de Y y N en 'store_and_fwd_flag':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar el DataFrame original\n",
    "print(\"Variable original:\")\n",
    "print(df['store_and_fwd_flag'].head())\n",
    "\n",
    "# Convertir 'Y' a 1 y 'N' a 0 usando map\n",
    "df['store_and_fwd_flag'] = df['store_and_fwd_flag'].map({'Y': 1, 'N': 0})\n",
    "\n",
    "# Mostrar el DataFrame convertido\n",
    "print(\"Variable después de la conversión:\")\n",
    "print(df['store_and_fwd_flag'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chequeo de variables númericas:\n",
    "\n",
    "> Primero vamos a ver si hay filas duplicadas y luego  vamos a chequear los limites de las columnas que tengan valores numéricos.  \n",
    "Ninguna columna numérica debería tener valores negativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para ver filas duplicadas\n",
    "df[df.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_antes = len(df)\n",
    "df = df.drop_duplicates()\n",
    "size_despues = len(df)\n",
    "print(f'se eliminaron: {size_antes-size_despues} filas duplicadas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se resetea\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_con_numeros = ['VendorID', 'passenger_count' ,'trip_distance','RatecodeID','PULocationID','DOLocationID','payment_type','fare_amount','extra','mta_tax','tip_amount','tolls_amount','improvement_surcharge','total_amount','congestion_surcharge']\n",
    "(df[columnas_con_numeros] < 0).any().to_frame('Menor que 0 ?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_con_negativos = ['fare_amount','extra','mta_tax','tip_amount','tolls_amount','improvement_surcharge','total_amount','congestion_surcharge']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in columnas_con_negativos:\n",
    "    print(c)\n",
    "    display(df[df[c] < 0][c].value_counts().to_frame())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eliminamos valores negativos y validamos las columnas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df[(df[columnas_con_negativos] >= 0).all(axis=1)]\n",
    "(df_filtered[columnas_con_negativos] < 0).any().to_frame('Menor que 0 ?')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_filtered\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().loc[['min', '25%', '50%', '75%', 'max']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo del IQR para la columna 'total_amount'\n",
    "Q1 = df['total_amount'].quantile(0.25)\n",
    "Q3 = df['total_amount'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define los límites inferior y superior para 'total_amount'\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filtra el DataFrame para mantener solo las filas donde 'total_amount' esté dentro de los límites\n",
    "df_sin_outliers = df[(df['total_amount'] >= lower_bound) & (df['total_amount'] <= upper_bound)]\n",
    "\n",
    "# Imprimir el número de filas eliminadas\n",
    "print(f\"Número de filas eliminadas: {len(df) - len(df_sin_outliers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sin_outliers.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sin_outliers.describe().loc[['min', '25%', '50%', '75%', 'max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sin_outliers['passenger_count'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_sin_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - ¿Qué puede decir acerca de las relaciones entre las variables de entrada?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df.corr()\n",
    "plt.figure(figsize=(15, 15))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "\n",
    "plt.title('Heatmap de Correlaciones')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen estadístico\n",
    "describe_stats = df['total_amount'].describe()\n",
    "print(describe_stats)\n",
    "\n",
    "sns.histplot(df['total_amount'], kde=False, bins=90,log_scale=False)\n",
    "plt.xlabel('Valor')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.title('Histograma con Seaborn')\n",
    "plt.show()\n",
    "\n",
    "# Crear un gráfico de caja\n",
    "sns.boxplot(data=df, y='total_amount', log_scale=False)\n",
    "plt.title('Gráfico de Caja')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Para elegir las variables de más importancia, vamos a  usar la técnica de filtrado de variables de forma estadística y técnicas embedded por árbol de decisión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Por varianza, se define un umbral mínimo para considerar variables. Por defecto elimina las features de varianza 0 (sin cambios) <br>\n",
    "Para asegurarnos que funcione agreguemos variables con esas condiciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = df.copy()\n",
    "_df['with_zero_variance'] = 10\n",
    "_df['with_low_variance'] = np.random.uniform(0, 0.2, _df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df.select_dtypes(include=['number']).var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def filter_by_variance(df, threshold):\n",
    "    # Columnas con varianza calculable\n",
    "    cols_con_varianza = df.var().index.values\n",
    "    _df = df[cols_con_varianza].copy()\n",
    "    print(f'columnas antes: {_df.columns.tolist()}')\n",
    "\n",
    "    # calculo varianzas\n",
    "    selector = VarianceThreshold(threshold=threshold)\n",
    "    vt = selector.fit(_df)\n",
    "\n",
    "    ## vt.get_support() me da los indices de las columnas que quedaron\n",
    "    _df = _df.loc[:, vt.get_support()]\n",
    "    print(f'columnas que quedan: {_df.columns.tolist()}')\n",
    "\n",
    "\n",
    "filter_by_variance(_df.select_dtypes(include=['number']), 0)\n",
    "print()\n",
    "filter_by_variance(_df.select_dtypes(include=['number']), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Eliminator a través de Arboles de Decisión con Regresión Lineal porque las variables son continuas.\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columnas_con_numeros = ['VendorID', 'passenger_count' ,'trip_distance','RatecodeID','PULocationID','DOLocationID','payment_type','fare_amount','extra','mta_tax','tip_amount','tolls_amount','improvement_surcharge',     'total_amount','congestion_surcharge']\n",
    "\n",
    "\n",
    "# Definir X e y. Supongamos que la etiqueta está en una columna llamada 'total_amount'\n",
    "X = df[columnas_con_numeros].drop(columns=['total_amount'])  # Elimina la columna de la etiqueta de X\n",
    "y = df[columnas_con_numeros]['total_amount']  # La columna de la etiqueta\n",
    "\n",
    "# Dividir el conjunto de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo Decision Tree (como las variables son continuas usando regresión)\n",
    "\n",
    "# Entrenar el modelo Decision Tree Regressor\n",
    "model = DecisionTreeRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predecir \n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcular métricas de evaluación para regresión\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse:.2f}')\n",
    "print(f'R^2 Score: {r2:.2f}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener la importancia de las características\n",
    "importances = model.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': importances})\n",
    "\n",
    "# Mostrar la importancia de las características\n",
    "print(\"Importancia de las características:\")\n",
    "print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preguntas interesantes para considerar aquí: (elija una o dos)\n",
    "\n",
    "• ¿Existe una manera de caracterizar los lugares más recurrentes para\n",
    "inicio/fin de viaje? \n",
    "\n",
    "- Habría que reemplazar PULocationID y DOLocationID por su respectivo valor zonal, usando la columna \"Zone\" de 'dataset\\taxi_zone_lookup.csv', y ver qué combinaciones son las mas frecuentes.\n",
    "    \n",
    "\n",
    "• ¿Cómo son los viajes típicamente en distancia y tiempo?\n",
    "\n",
    "- Para la Distancia: usar trip_distance\n",
    "- Para el Tiempo:Crear una nueva columna restanto tpep_dropoff_datetime y tpep_pickup_datetime, de aqui tenemos el tiempo total de viaje \n",
    "\n",
    "- IDEA: En que franja horaria ocurre la mayor cantidad de viajes?\n",
    "\n",
    "\n",
    "\n",
    "• ¿Podremos segmentar los viajes de alguna manera? (clusterización)\n",
    "\n",
    "- Ni idea, capaz por Mes y ver qué mes tiene mas viajes, cuales son más caros, etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
